https://www.udemy.com/course/70533-azure/

View it
Section 5: Manage Azure AD objects
Users and groups, add roles in Azure active directory, many built in.
Add company user or invite guest user or register device.

Section 6: Manage role-based access control (RBAC)
When you have user or group, you can restricted the access on vm, vnet, rg with access control (IAM) on the blade for the vm, vnet or rg.
Add role assignment to user, group or service principal.

* Rule, give the least permission.

We can create custom role (AD) also, if the built in is not enough, for example on the rg.
IAM->Create a custom role
Add permissions
Exclude permissions

Lab:
Add users and groups, give them access to different resources, test it in the portal.

https://follow-e-lo.com/2021/09/01/5-min-azure-active-directory-and-iam/


Section 8: Create and configure storage accounts

Fundamental of the cloud, place to store files in azure.
1 Container storage for files, blobs.
2 Managed storage backend for VM's (C,D, HD etc)

Create storage account:
Basic:
Performance
Standard, most scenarios.
Premium, (SSD, but more cost) for low latency.
Redundancy:
GRS, Geo-redundancy storage, in region and a copy of files in secondary region. 6 Copies
LRS, 1 file in region, 2 copy of files in same region. 3 Copies. Low cost
ZRS, similar LRS, but separate datacenters power, water etc. That is zones.
GZRS, combines GRS and ZRS.

Advanced:
Security, https.
Encrypted, they are by default, but can encrypt at rest.
Public acces, ACL, No public access (then use IAM or RBAC)
Enable key access
TLS, keep
Data lake gen2, big data.
Blob, table, queue and azure files.
NFS, network file share (mount, T or F drive for example)
Access tier:
Hot,
Cool,
Cannot set archive default, but move after.
Large files, 100 TB.
Tables and Queue (FIFO), control the security key's for that.

Networking:
Public endpoint (is is secure, but have to protect the key's
Public selected networks
Private.
Routing
Example account in Canada, Client in Japan.
MS,Travel through MS global network as long as possible (small charge)
Internet, the pops out of account as close as possible to st account then public internet to Japan. (no charge)

Data protection
Recovery, straight forward, keep for x days etc.
Tracking and version and notification on change.

Tags, review and create.

Access keys and SAS (for third parties)

A quick look at the storage account:
properties tab: features
monitoring, egress (leaving from azure) ingress (in to azure)
capabilities: upgrade and more, static website, data protection, lifecycle,
CDN, custom domain etc
advisor:
tutorials:
developer coder:

Can access it through access key, 2 keys, for security and deploy key and not break apps or other.
key1, keep it secure!! If it exposed we muste generate a new key and use the other in the mean time.

Shared access signature SAS (a URI, HTTP/HTTPS), delegate access to application or individuals without giving key.
for example just read on a , just access to a file, date limit, filter by ip and so on.
Then we sign with key1 and generate a SAS and connection string.

If you generate a new key 1 or 2, then the SAS that used that key must also be generated again.

Storage explorer:
The best way to interact is if you download storage explorer or programmatic ways, API's or SDK.

Log analytics: 
Monitoring on the storage account
Insight, overvire, failures, performance etc.
Alerts, if 100gb then alert etc. Set up action group (cost) a mail if limit is reached.
Metrics, create our own graphs.
Workbook, predefined view of storage account.
Diagnostics, is not turned on by default. View logs, how does access, read, write, transaction. 
Where should it go, a log file or Azure analytics, aarchive, stream to event hub (trigger other actions) or send to partner.
Logs, logs analytics, pre written query or write custom query in then language KUSTO

Redundant storage:
LRS, (canda central example) for every file there are additional two copies, total three copies.
GRS (same as LRS, but two regions), storage account configuration, can change it there.
Geo replication, can view both regions and do a fail over. Prepare for failover button (swap manually from primary to secondary)


Copy files with AzCopy:
https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10

AzCopy is a command-line utility that you can use to copy blobs or files to or from a storage account. 
This article helps you download AzCopy, connect to your storage account, and then transfer files.

Example, copy a file from one container to another.
It does not need to download the files to your local and then upload, it does all inside Azure.

Available Commands:
  bench       Performs a performance benchmark
  completion  generate the autocompletion script for the specified shell
  copy        Copies source data to a destination location
  doc         Generates documentation for the tool in Markdown format
  env         Shows the environment variables that you can use to configure the behavior of AzCopy.
  help        Help about any command
  jobs        Sub-commands related to managing jobs
  list        List the entities in a given resource
  login       Log in to Azure Active Directory (AD) to access Azure Storage resources.
  logout      Log out to terminate access to Azure Storage resources.
  make        Create a container or file share.
  remove      Delete blobs or files from an Azure storage account
  sync        Replicate source to the destination location

It does not support keys, but accees from Azure AD or SAS token


azcopy copy 'https://<source-storage-account-name>.blob.core.windows.net/<container-name>/<blob-path><SAS-token>' 'https://<destination-storage-account-name>.blob.core.windows.net/<container-name>/<blob-path>'

Mini lab:
Basic:
Create a storage account
rg:testit2-rg
storage account name: testit2storage
region: we
performance: Standard
Redundancy:lrs
Advanced:
Keep default, Require secure transfer for REST API,tlf 1.2 access tiers, hot
Networking: Public endpoint (all networks), it is secure but we must protect the keys
Data protection, tags; defaultReview + create

Now go inside testit2storage->Data storage->container
create testit2container, public access level private.
(the size is what we use, no matter what it it rounded up to nearest 1 gb for charge)

Upload a file to testit2container, Lorem Ipsum.txt

create another testit3container, public access level private.

Now generate SAS on the file, and copy the Blob SAS URL.

On the testit3container, go to generate sas and on permissions, all (read, write, since we need to write the file, etc) on that container.
Now get the SAS URL and copy it to the script.

Run cmd as admin and navigate to the file downloaded and run:
azcopy login --tenant-id "[TenantID]"

azcopy login --tenant-id "MY-SECRET-TENANT-ID"
To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code MY-SECRET-CODE to authenticate.

The run: (on windows use "", not '')
azcopy copy "source" "destination"

Result:
Job 32f2137f-6126-574f-5cc4-acd4bad12c57 has started
Log file is located at: C:\Users\admin\.azcopy\32f2137f-6126-574f-5cc4-acd4bad12c57.log

0.0 %, 0 Done, 0 Failed, 1 Pending, 0 Skipped, 1 Total,


Job 32f2137f-6126-574f-5cc4-acd4bad12c57 summary
Elapsed Time (Minutes): 0.0335
Number of File Transfers: 1
Number of Folder Property Transfers: 0
Total Number of Transfers: 1
Number of Transfers Completed: 1
Number of Transfers Failed: 0
Number of Transfers Skipped: 0
TotalBytesTransferred: 586
Final Job Status: Completed


Access tiers:
Hot or Cool, hot is default.
So depending on tier,
you can get charged less for storage or more for access 
or more for storage and less for access 
or in-between state, which is the hot. (Most will be hot)
Cool, 50 % cheaper than hot, but access cost is double.
Can change hot or cool (storage account configuration), and can do it pr file also. (Container-> file->change tier)
two more tiers:
archive cheaper, but way more cost to access, only for emergency, backup from 1 year ago. This tier can take several hours to retrive....slow or ask for high priority.

Pricing $:
First 50 terabyte (TB) / month
Premium, 0.15 per gb
Hot, 0.0184 per gb
Cool, 0.01 per gb
archive, 0.002 per gb

Cool, minimum of 30 days charge per file
Archive, minimum 100 days charge per file

Most expensive is Premium.
When you create the storage account->performance, premium or Standard
Premium 10x faster then Standard and better latency.

Use calculator, and check read, write etc
So if hundred's of reads per second, you can save money on the premium tier vs the hot because the access cost is so much lower.


Lifecycle management:
Transistion to appropriate access tiers, hot,cool based on rules.
For example 30 days after modification move to cool, 100 d move to archive.
200 days, delete it.

AD Access control for storage:
Object replication:

Lab:




Section 9
Section 10
Section 11
Section 12
Section 13
Section [...]
Section 25











