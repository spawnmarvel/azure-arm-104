https://www.udemy.com/course/70533-azure/

View it
Section 5: Manage Azure AD objects
Users and groups, add roles in Azure active directory, many built in.
Add company user or invite guest user or register device.

Section 6: Manage role-based access control (RBAC)
When you have user or group, you can restricted the access on vm, vnet, rg with access control (IAM) on the blade for the vm, vnet or rg.
Add role assignment to user, group or service principal.

* Rule, give the least permission.

We can create custom role (AD) also, if the built in is not enough, for example on the rg.
IAM->Create a custom role
Add permissions
Exclude permissions

Lab:
Add users and groups, give them access to different resources, test it in the portal.

https://follow-e-lo.com/2021/09/01/5-min-azure-active-directory-and-iam/


Section 8: Create and configure storage accounts

Fundamental of the cloud, place to store files in azure.
1 Container storage for files, blobs.
2 Managed storage backend for VM's (C,D, HD etc)

Create storage account:
Basic:
Performance
Standard, most scenarios.
Premium, (SSD, but more cost) for low latency.
Redundancy:
GRS, Geo-redundancy storage, in region and a copy of files in secondary region. 6 Copies
LRS, 1 file in region, 2 copy of files in same region. 3 Copies. Low cost
ZRS, similar LRS, but separate datacenters power, water etc. That is zones.
GZRS, combines GRS and ZRS.

Advanced:
Security, https.
Encrypted, they are by default, but can encrypt at rest.
Public acces, ACL, No public access (then use IAM or RBAC)
Enable key access
TLS, keep
Data lake gen2, big data.
Blob, table, queue and azure files.
NFS, network file share (mount, T or F drive for example)
Access tier:
Hot,
Cool,
Cannot set archive default, but move after.
Large files, 100 TB.
Tables and Queue (FIFO), control the security key's for that.

Networking:
Public endpoint (is is secure, but have to protect the key's
Public selected networks
Private.
Routing
Example account in Canada, Client in Japan.
MS,Travel through MS global network as long as possible (small charge)
Internet, the pops out of account as close as possible to st account then public internet to Japan. (no charge)

Data protection
Recovery, straight forward, keep for x days etc.
Tracking and version and notification on change.

Tags, review and create.

Access keys and SAS (for third parties)

A quick look at the storage account:
properties tab: features
monitoring, egress (leaving from azure) ingress (in to azure)
capabilities: upgrade and more, static website, data protection, lifecycle,
CDN, custom domain etc
advisor:
tutorials:
developer coder:

Can access it through access key, 2 keys, for security and deploy key and not break apps or other.
key1, keep it secure!! If it exposed we muste generate a new key and use the other in the mean time.

Shared access signature SAS (a URI, HTTP/HTTPS), delegate access to application or individuals without giving key.
for example just read on a , just access to a file, date limit, filter by ip and so on.
Then we sign with key1 and generate a SAS and connection string.

If you generate a new key 1 or 2, then the SAS that used that key must also be generated again.

Storage explorer:
The best way to interact is if you download storage explorer or programmatic ways, API's or SDK.

Log analytics: 
Monitoring on the storage account
Insight, overvire, failures, performance etc.
Alerts, if 100gb then alert etc. Set up action group (cost) a mail if limit is reached.
Metrics, create our own graphs.
Workbook, predefined view of storage account.
Diagnostics, is not turned on by default. View logs, how does access, read, write, transaction. 
Where should it go, a log file or Azure analytics, aarchive, stream to event hub (trigger other actions) or send to partner.
Logs, logs analytics, pre written query or write custom query in then language KUSTO

Redundant storage:
LRS, (canda central example) for every file there are additional two copies, total three copies.
GRS (same as LRS, but two regions), storage account configuration, can change it there.
Geo replication, can view both regions and do a fail over. Prepare for failover button (swap manually from primary to secondary)


Copy files with AzCopy:
https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10

AzCopy is a command-line utility that you can use to copy blobs or files to or from a storage account. 
This article helps you download AzCopy, connect to your storage account, and then transfer files.

Example, copy a file from one container to another.
It does not need to download the files to your local and then upload, it does all inside Azure.

Available Commands:
  bench       Performs a performance benchmark
  completion  generate the autocompletion script for the specified shell
  copy        Copies source data to a destination location
  doc         Generates documentation for the tool in Markdown format
  env         Shows the environment variables that you can use to configure the behavior of AzCopy.
  help        Help about any command
  jobs        Sub-commands related to managing jobs
  list        List the entities in a given resource
  login       Log in to Azure Active Directory (AD) to access Azure Storage resources.
  logout      Log out to terminate access to Azure Storage resources.
  make        Create a container or file share.
  remove      Delete blobs or files from an Azure storage account
  sync        Replicate source to the destination location

It does not support keys, but accees from Azure AD or SAS token


azcopy copy 'https://<source-storage-account-name>.blob.core.windows.net/<container-name>/<blob-path><SAS-token>' 'https://<destination-storage-account-name>.blob.core.windows.net/<container-name>/<blob-path>'

Mini lab:
Basic:
Create a storage account
rg:testit2-rg
storage account name: testit2storage
region: we
performance: Standard
Redundancy:lrs
Advanced:
Keep default, Require secure transfer for REST API,tlf 1.2 access tiers, hot
Networking: Public endpoint (all networks), it is secure but we must protect the keys
Data protection, tags; defaultReview + create

Now go inside testit2storage->Data storage->container
create testit2container, public access level private.
(the size is what we use, no matter what it it rounded up to nearest 1 gb for charge)

Upload a file to testit2container, Lorem Ipsum.txt

create another testit3container, public access level private.

Now generate SAS on the file, and copy the Blob SAS URL.

On the testit3container, go to generate sas and on permissions, all (read, write, since we need to write the file, etc) on that container.
Now get the SAS URL and copy it to the script.

Run cmd as admin and navigate to the file downloaded and run:
azcopy login --tenant-id "[TenantID]"

azcopy login --tenant-id "MY-SECRET-TENANT-ID"
To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code MY-SECRET-CODE to authenticate.

The run: (on windows use "", not '')
azcopy copy "source" "destination"

Result:
Job 32f2137f-6126-574f-5cc4-acd4bad12c57 has started
Log file is located at: C:\Users\admin\.azcopy\32f2137f-6126-574f-5cc4-acd4bad12c57.log

0.0 %, 0 Done, 0 Failed, 1 Pending, 0 Skipped, 1 Total,


Job 32f2137f-6126-574f-5cc4-acd4bad12c57 summary
Elapsed Time (Minutes): 0.0335
Number of File Transfers: 1
Number of Folder Property Transfers: 0
Total Number of Transfers: 1
Number of Transfers Completed: 1
Number of Transfers Failed: 0
Number of Transfers Skipped: 0
TotalBytesTransferred: 586
Final Job Status: Completed


Access tiers:
Hot or Cool, hot is default.
So depending on tier,
you can get charged less for storage or more for access 
or more for storage and less for access 
or in-between state, which is the hot. (Most will be hot)
Cool, 50 % cheaper than hot, but access cost is double.
Can change hot or cool (storage account configuration), and can do it pr file also. (Container-> file->change tier)
two more tiers:
archive cheaper, but way more cost to access, only for emergency, backup from 1 year ago. This tier can take several hours to retrive....slow or ask for high priority.

Pricing $:
First 50 terabyte (TB) / month
Premium, 0.15 per gb
Hot, 0.0184 per gb
Cool, 0.01 per gb
archive, 0.002 per gb

Cool, minimum of 30 days charge per file
Archive, minimum 100 days charge per file

Most expensive is Premium.
When you create the storage account->performance, premium or Standard
Premium 10x faster then Standard and better latency.

Use calculator, and check read, write etc
So if hundred's of reads per second, you can save money on the premium tier vs the hot because the access cost is so much lower.


Lifecycle management:
Transistion to appropriate access tiers, hot,cool based on rules.
For example 30 days after modification move to cool, 100 d move to archive.
200 days, delete it.

AD Access control for storage:
Access keys (full owner) or SAS to limit permissions.
Third way is access control (IAM)

Object replication:
Copy new files to different storage account.
Can copy in both direction.
Why do you want to do this?
After proccessing is done, move to "done container" (etc.)
Both source/destination must be same tiers.
When object replication is enabled, blobs are copied asynchronously from a source storage account to a destination account.
So when the a new file is uploaded  to source, it it replicated to the backup container. 
Check that blob change feed is on, It uses Blob change feed, 

Lab:

https://github.com/MicrosoftLearning/AZ-104-MicrosoftAzureAdministrator/blob/master/Instructions/Labs/LAB_07-Manage_Azure_Storage.md

You need to evaluate the use of Azure storage for storing files residing currently in on-premises data stores. While majority of these files are not accessed frequently, there are some exceptions. You would like to minimize cost of storage by placing less frequently accessed files in lower-priced storage tiers. You also plan to explore different protection mechanisms that Azure Storage offers, including network access, authentication, authorization, and replication. Finally, you want to determine to what extent Azure Files service might be suitable for hosting your on-premises file shares.

In this lab, you will:

    Task 1: Provision the lab environment
    Task 2: Create and configure Azure Storage accounts
    Task 3: Manage blob storage
    Task 4: Manage authentication and authorization for Azure Storage
    Task 5: Create and configure an Azure Files shares
    Task 6: Manage network access for Azure Storage

Hm, all the files are missing from the lab, must try to replicate the lab environment.


Exercise 1 
Task 1: Provision the lab environment
In this task, you will deploy an Azure virtual machine that you will use later in this lab.
(did not do 6 deployed a vm)

az login --tenant
$loc = "WEST EUROPE"
$rgName = "az104-07-rg0"
New-AzResourceGroup -Name $rgName -Location $loc

Get-AzResourceGroup -ResourceGroupName $rgName

(Remove-AzResourceGroup -Name $rgName)

ResourceGroupName : az104-07-rg0
Location          : westeurope
ProvisioningState : Succeeded
Tags              :

Task 2: Create and configure Azure Storage accounts
In this task, you will create and configure an Azure Storage account.

Resource group 	the name of a new resource group az104-07-rg1
Storage account name az10407rg1account
Create it
Setting 	            Value
Subscription 	        the name of the Azure subscription you are using in this lab
Resource group 	      the name of a new resource group az104-07-rg1
Storage account name 	any globally unique name between 3 and 24 in length consisting of letters and digits
Location 	            East US
Performance 	        Standard
Redundancy 	          Geo-redundant storage (GRS)
Leave the rest default.
When done:

On the Storage account blade, in the Data management section, click Geo-replication and note the secondary location.
Primary = East US
Secondary= West US

On the Storage account blade, in the Settings section, select Configuration, in the Replication drop-down list select Locally redundant storage (LRS) and save the change.
Primary = East US

Task 3: Manage blob storage
In this task, you will create a blob container and upload a blob into it.

Setting 	            Value
Name                  az10407container
Public access level 	Private (no anonymous access)

Uploaded Lorem Ipsum.txt to az10407container


Task 4: Manage authentication and authorization for Azure Storage
In this task, you will configure authentication and authorization for Azure Storage.

Navigate to the file Lorem Ipsum.txt in az10407container and get the URL

https://az10407rg1account.blob.core.windows.net/az10407container/Lorem Ipsum.txt

Open a new browser, and it should be denied, You should be presented with an XML-formatted message stating ResourceNotFound or PublicAccessNotPermitted.


<Error>
<Code>ResourceNotFound</Code>
<Message>
The specified resource does not exist. RequestId:3cb4c332-e01e-0012-355e-c3de75000000 Time:2021-10-17T13:52:47.7710532Z
</Message>
</Error>


switch to the the Generate SAS tab.

Setting 	            Value
Signing key 	        Key 1
Permissions 	        Read
Start date 	          yesterday's date
Start time 	          current time
Expiry date 	        tomorrow's date
Expiry time 	        current time
Allowed IP addresses 	leave blank



Click Generate SAS token and URL.

Click Copy to clipboard button next to the Blob SAS URL entry.

https://az10407rg1account.blob.core.windows.net/az10407container/Lorem%20Ipsum.txt?sp=r&st=2021-10-16T13:54:09Z&se=2021-10-18T21:54:09Z&spr=https&sv=2020-08-04&sr=b&sig=CtBMrOib0Y760oxvORxLD2eM0dlFozFZNAVpKhcJKFA%3D

Open another browser window by using InPrivate mode and navigate to the URL you copied in the previous step.

Lorem Ipsum is simply dummy text of the printing and typesetting industry. 
[...]

Click the Switch to the Azure AD User Account link next to the Authentication method label.


    Note: You can see an error when you change the authentication method (the error is "You do not have permissions to list the data using your user account with Azure AD"). It is expected.

    Note: At this point, you do not have permissions to change the Authentication method.


On the az10407container blade, click Access Control (IAM).


In the Add section, click Add a role assignment.

On the Add role assignment blade, specify the following settings:

Setting 	        Value
Role 	            Storage Blob Data Owner
Assign access to 	User, group, or service principal
Select 	          the name of your user account


Save the change and return to the Overview blade of the az10407container container and verify that you can change the Authentication method to (Switch to Azure AD User Account).
Authentication method: Access key (Switch to Azure AD User Account)
Location: az10407container


Task 5: Create and configure an Azure Files shares
In this task, you will create and configure Azure Files shares and use a VM to store them

Note: Before you start this task, verify that the virtual machine you provisioned in the first task of this lab is running.
Will just use the portal and create a VM:

Rg                  az104-07-rg0
Virtual macine name az104testVM
region              West EUROPE
Image               Windows Server 2016 Datacenter -Gen2
Size                B2s  General purpose, 2 vcpu, 4 gib memory
u                   Ledzepplin, Ledzepplin and the numbers
Pub inbound por     Allowe selected
Select inbound por  RDP, 3389
Disk                Standard SSD, lrs
Network             create all new and keep default
Management          keep default
Advanced            Keep default
Tags                none
Review + create

Price, 0.0769 AUD/hr

PS C:\Users\Ledzepplin> hostname
az104testVM
PS C:\Users\Ledzepplin> Get-Date
Sunday, October 17, 2021 2:20:02 PM


navigate back to the blade of the storage account az10407rg1account

Click + File share and create a file share with the following settings:

Setting 	Value
Name 	    az104-07-share



Click the newly created file share and click Connect.

On the Connect blade, ensure that the Windows tab is selected. Below you will find a grey textbox with a script, in the bottom right corner of that box hover over the pages icon and click Copy to clipboard.


$connectTestResult = Test-NetConnection -ComputerName az10407rg1account.file.core.windows.net -Port 445
if ($connectTestResult.TcpTestSucceeded) {
    # Save the password so the drive will persist on reboot
    cmd.exe /C "cmdkey /add:`"az10407rg1account.file.core.windows.net`" /user:`"localhost\az10407rg1account`" /pass:`"A SECRET KEY, BUT NOT THIS`""
    # Mount the drive
    New-PSDrive -Name Z -PSProvider FileSystem -Root "\\az10407rg1account.file.core.windows.net\az104-07-share" -Persist
} else {
    Write-Error -Message "Unable to reach the Azure storage account via port 445. Check to make sure your organization or ISP is not blocking port 445, or use Azure P2S VPN, Azure S2S VPN, or Express Route to tunnel SMB traffic over a different port."
}


On the Azure portal, search for and select Virtual machines, and, in the list of virtual machines, az104testVM.

On the az104testVM blade, in the Operations section, click Run command.

On the az104testVM - Run command blade, click RunPowerShellScript.

On the Run Command Script blade, paste the script you copied earlier in this task into the PowerShell Script pane and click Run.

Verify that the script completed successfully.

Run Command Script
RunPowerShellScript

Output
CMDKEY: Credential added successfully.

Name           Used (GB)     Free (GB) Provider      Root                      
----           ---------     --------- --------      ----                      
Z                   0.00       5120.00 FileSystem    \\az10407rg1account.fil...

Replace the content of the PowerShell Script pane with the following script and click Run:


New-Item -Type Directory -Path 'Z:\az104testVM-folder'

New-Item -Type File -Path 'Z:\az104testVM-folder\az104testVMfile.txt'

Output
    Directory: Z:\


Mode                LastWriteTime         Length Name                          
----                -------------         ------ ----                          
d-----       10/17/2021   2:29 PM                az104testVM-folder            


    Directory: Z:\az104testVM-folder


Mode                LastWriteTime         Length Name                          
----                -------------         ------ ----                          
-a----       10/17/2021   2:29 PM              0 az104testVMfile.txt 



Navigate back to the az104-07-share verify that az104testVM-folder appears in the list of folders.
Verify that the az104testVM-folder\az104testVMfile.txt appears

Jepp it is there, here is the URL from the file:
https://az10407rg1account.file.core.windows.net/az104-07-share/az104testVM-folder/az104testVMfile.txt

Make a new file, navigate to z104testVM

Run Command Script
RunPowerShellScript

We have the folder, we are just creating a new file.

New-Item -Type File -Path 'Z:\az104testVM-folder\az104test2.txt'

New-Item -Type File -Path 'Z:\az104testVM-folder\az104test3.txt'

Directory: Z:\az104testVM-folder


Mode                LastWriteTime         Length Name                          
----                -------------         ------ ----                          
-a----       10/17/2021   2:40 PM              0 az104test3.txt 

Navigate back to the az104-07-share verify that the two new files are there (all 3 files are there, nice)


Task 6: Manage network access for Azure Storage
In this task, you will configure network access for Azure Storage.

In the Azure portal, navigate back to the blade of the storage account you created in the first task of this lab and, 
in the Security + Networking section, click Networking and then click Firewalls and virtual networks.

az10407rg1account



Click the Selected networks option and review the configuration settings that become available once this option is enabled.

Note: You can use these settings to configure direct connectivity between Azure virtual machines on designated subnets of virtual networks and the storage account by using service endpoints.

Click the checkbox Add your client IP address and save the change.

Open another browser window by using InPrivate mode and navigate to the blob SAS URL you generated in the previous task.
Click the checkbox Add your client IP address and save the change.

It only supports public ip, so this is denied as it should be.

Change back to Allow access from All networks:

PS C:\Users\admin> Invoke-WebRequest -Uri "https://az10407rg1account.blob.core.windows.net/az10407container/Lorem%20Ipsum.txt?sp=r&st=2021-10-16T13:54:09Z&se=2021-10-18T21:54:09Z&spr=https&sv=2020-08-04&sr=b&sig=CtBMrOib0Y760oxvORxLD2eM0dlFozFZNAVpKhcJKFA%3D
>> "


StatusCode        : 200
StatusDescription : OK
Content           : Lorem Ipsum is simply dummy text of the printing and typesetting industry.
                    Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,
                    when an unknown printer took a galley of ty...
RawContent        : HTTP/1.1 200 OK
  

Click the Selected networks option

PS C:\Users\admin> Invoke-WebRequest -Uri "https://az10407rg1account.blob.core.windows.net/az10407container/Lorem%20Ipsum.txt?sp=r&st=2021-10-16T13:54:09Z&se=2021-10-18T21:54:09Z&spr=https&sv=2020-08-04&sr=b&sig=CtBMrOib0Y760oxvORxLD2eM0dlFozFZNAVpKhcJKFA%3D
>> "
Invoke-WebRequest : AuthorizationFailureThis request is not authorized to perform this operation.
RequestId:ce58a5ec-701e-005d-2d67-c3af21000000 Time:2021-10-17T14:55:57.5894493Z
At line:1 char:1


Clean up resources, delete all rg'selected

Get-AzResourceGroup -Name 'az104-07*' | Remove-AzResourceGroup -Force -AsJob

Section 9 Import and export data to Azure

Storage explorer browser and software to download to place
az copy, cmd

What if much data, terra byte? (time, band width)

Moving large files:
Azure portal type: import/export jobs
Export:
Shipping, send the disk FDEX, UPS etc.
Import:
Shipping, get a disk, ship it FDEX, UPS etc.

100 TB data box, 1 PB data box heavy or 8 TB SSD disk up to 40TB

Blob storage:
Account style:
Blobstorage:
create a new container with access levels and IAM.
(for uploading files and copy the URL and access it, embed, for example images, js, pdf, video, static files etc. for website)
But not the best solution / or cheap for static files.

CDN: Content delivery network
CDN better optimizations for static files.
Azure Content Delivery Network (CDN) is a global CDN solution for delivering high-bandwidth content. 
It can be hosted in Azure or any other location. With Azure CDN, you can cache static objects loaded from Azure Blob storage, 
a web application, or any publicly accessible web server, by using the closest point of presence (POP) server. 
Azure CDN can also accelerate dynamic content, which cannot be cached, by leveraging various network and routing optimizations.

CDN works globally, does not belong to a rg in particular.
It allows for reduced traffic coming into webserves for static files.

4 differnt service options:
Compare CDN product features
(Own domain, certificate, HTTPS etc)

Use an endpoint URL and cache it to the CDN.
How to update cache? 
Scott Duffy:
"Purge CDN"
and Caching rules.


Section 10 Configure Azure Files
Azure File share.
Connect to it like mounted drive, drive letter, finished commands available.
(Many ISP, block port 445 (SMB), reason for blocked is for security reason
(If a home computer has the C drive open,easy to hack it.)

Scenario:
10 VM in a LB cluster that needs to share a set of files,
then you create one file mount.
Mount all of these in those servers and they can for example write their logs there.

Azure File sync
Use file sync agent, download.
Then run on your local server and it lets your files be in sync with Azure File share.

Create azure file sync
1 sync group is the file share you want to sync with.
2 Configure the agent or register the server (445 port)
3 Azure will sync it

Troubleshoot Azure File sync

follow the article:

https://docs.microsoft.com/en-us/azure/storage/file-sync/file-sync-troubleshoot?tabs=portal1%2Cazure-portal

Strong point:
sync is delayed or not working? = recreate sync group or register the server again? = No, MS says no.
Turn on logging, more verbose

questions:
The SMB protocol requires TCP port 445 to be open; connections will fail if port 445 is blocked.

The Azure File Sync service is used as a file distribution service. The ideal solution to use here is the Content Delivery service. For more information on the File Sync Service, one can go to: https://docs.microsoft.com/en-us/azure/storage/files/storage-sync-files-planning

Section 11 Implement backup and recovery
Section 12 Azure Virtual Machines
Section 13
Section [...]
Section 25










